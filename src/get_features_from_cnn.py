#!/usr/bin/env python
# -*- coding: utf-8 -*-

# from cnnkeras import *

import pandas as pd
import sys
import os
import pickle
import argparse

from vgg16 import VGG16
from resnet50 import ResNet50
from vgg19 import VGG19

from keras.preprocessing import image
from imagenet_utils import preprocess_input

import numpy as np
from functools import reduce
from operator import mul
from scipy.sparse import csr_matrix

# Variable specific to vgg-16/vgg-19
img_width = 224
img_height = 224


# Feature extractor
def get_features(model, df):
    features = []
    n_images = len(df)
    img_paths = list(df.local_image)
    for idx, img_path in enumerate(img_paths):
        print('getting features for %s %d/%d' %
              (img_path, idx+1, n_images))
        # Resize image to be 224x224
        img = image.load_img(img_path, target_size=(224, 224))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        y = model.predict(x)
        # Vectorize the 7x7x512 tensor
        y = y.reshape(reduce(mul, y.shape, 1))
        features.append(y)
    return features


def main(argv):
    parser = argparse.ArgumentParser()
    parser.add_argument('-i', '--input_file',
                        help="input file generated by get_poster.py",
                        default="./cnn_posters.p")
    parser.add_argument('-o', '--output_file',
                        help="output pickle file used with features",
                        default='./cnn_posters_features.p')
    args = parser.parse_args()

    df = pickle.load(open(args.input_file, 'rb'))

    # Load VGG19, guys you better have a GPU...
    model_ = VGG16(weights='imagenet', include_top=False)
    df['features'] = get_features_cnn(model_, df)

    pickle.dump(df, open(args.output_file, 'wb'))

if __name__ == "__main__":
    main(sys.argv[1:])